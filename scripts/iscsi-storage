#!/usr/bin/env bash
set -euo pipefail

# Manage Kubernetes workloads using iSCSI storage.
#
# Commands:
#   status   - Show iSCSI workloads and their current state
#   restart  - Restart pods using iSCSI storage (quick recovery)
#   down     - Scale down workloads for storage maintenance
#   up       - Restore workloads after maintenance
#
# The down/up workflow is preferred for Synology updates since it ensures
# clean iSCSI unmounts before the storage goes offline.

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m'

STORAGE_CLASS="synology-iscsi"
ANNOTATION_KEY="iscsi-storage/pre-maintenance-replicas"

timestamp() {
    date '+%Y-%m-%d %H:%M:%S'
}

log_info() {
    echo -e "${CYAN}[$(timestamp)]${NC} ${BLUE}[INFO]${NC} $*"
}

log_success() {
    echo -e "${CYAN}[$(timestamp)]${NC} ${GREEN}[SUCCESS]${NC} $*"
}

log_warn() {
    echo -e "${CYAN}[$(timestamp)]${NC} ${YELLOW}[WARN]${NC} $*"
}

log_error() {
    echo -e "${CYAN}[$(timestamp)]${NC} ${RED}[ERROR]${NC} $*"
}

cleanup() {
    local pids
    pids=$(jobs -p 2>/dev/null || true)
    if [[ -n "$pids" ]]; then
        # shellcheck disable=SC2086
        kill $pids 2>/dev/null || true
    fi
}
trap cleanup EXIT INT TERM

usage() {
    cat <<EOF
Usage: $(basename "$0") <command> [options]

Manage Kubernetes workloads using iSCSI storage.

Commands:
  status    Show iSCSI workloads and their current state
  restart   Restart pods using iSCSI storage (quick recovery)
  down      Scale down workloads for storage maintenance
  up        Restore workloads after maintenance

Run '$(basename "$0") <command> --help' for command-specific help.

Workflow for Synology updates:
  1. Run 'iscsi-storage down' to safely scale down workloads
  2. Apply Synology DSM update and wait for reboot
  3. Run 'iscsi-storage up' to restore workloads

The restart command is for quick recovery when LUNs haven't gone stale.
For storage maintenance (reboots, updates), use down/up instead.
EOF
    exit 1
}

# Find all PVCs using synology-iscsi storage class
discover_iscsi_pvcs() {
    kubectl get pvc -A -o json | jq -r --arg sc "$STORAGE_CLASS" \
        '.items[] | select(.spec.storageClassName == $sc) | "\(.metadata.namespace)/\(.metadata.name)"'
}

# Find pods using a specific PVC
find_pods_for_pvc() {
    local namespace=$1
    local pvc_name=$2
    kubectl get pods -n "$namespace" -o json 2>/dev/null | \
        jq -r --arg pvc "$pvc_name" \
        '.items[] | select(.spec.volumes[]?.persistentVolumeClaim?.claimName == $pvc) | .metadata.name' || true
}

# Get the owning workload for a pod (Deployment, StatefulSet, etc.)
get_pod_owner() {
    local namespace=$1
    local pod_name=$2

    local owner_json
    owner_json=$(kubectl get pod -n "$namespace" "$pod_name" -o json 2>/dev/null | \
        jq -r '.metadata.ownerReferences[0] | "\(.kind)/\(.name)"' || echo "")

    if [[ -z "$owner_json" || "$owner_json" == "null/null" ]]; then
        echo ""
        return
    fi

    local owner_kind owner_name
    owner_kind=$(echo "$owner_json" | cut -d/ -f1)
    owner_name=$(echo "$owner_json" | cut -d/ -f2)

    # If owned by ReplicaSet, trace up to Deployment
    if [[ "$owner_kind" == "ReplicaSet" ]]; then
        local rs_owner
        rs_owner=$(kubectl get rs -n "$namespace" "$owner_name" -o json 2>/dev/null | \
            jq -r '.metadata.ownerReferences[0] | "\(.kind)/\(.name)"' || echo "")
        if [[ -n "$rs_owner" && "$rs_owner" != "null/null" ]]; then
            owner_kind=$(echo "$rs_owner" | cut -d/ -f1)
            owner_name=$(echo "$rs_owner" | cut -d/ -f2)
        fi
    fi

    echo "${owner_kind,,}/$owner_name"
}

# Get current replica count for a workload
get_replicas() {
    local namespace=$1
    local kind=$2
    local name=$3
    kubectl get "$kind" -n "$namespace" "$name" -o jsonpath='{.spec.replicas}' 2>/dev/null || echo "0"
}

# Build list of workloads using iSCSI storage
# Returns JSON array of workload objects
discover_workloads() {
    local iscsi_pvcs
    iscsi_pvcs=$(discover_iscsi_pvcs)

    if [[ -z "$iscsi_pvcs" ]]; then
        echo "[]"
        return
    fi

    declare -A workloads_seen
    local workloads_json="[]"

    while IFS= read -r pvc_ref; do
        local namespace pvc_name
        namespace=$(echo "$pvc_ref" | cut -d/ -f1)
        pvc_name=$(echo "$pvc_ref" | cut -d/ -f2)

        local pods
        pods=$(find_pods_for_pvc "$namespace" "$pvc_name")

        while IFS= read -r pod_name; do
            [[ -z "$pod_name" ]] && continue

            local owner
            owner=$(get_pod_owner "$namespace" "$pod_name")
            [[ -z "$owner" ]] && continue

            local kind name
            kind=$(echo "$owner" | cut -d/ -f1)
            name=$(echo "$owner" | cut -d/ -f2)

            local workload_key="$namespace/$kind/$name"
            if [[ -z "${workloads_seen[$workload_key]:-}" ]]; then
                workloads_seen[$workload_key]=1
                local replicas
                replicas=$(get_replicas "$namespace" "$kind" "$name")
                workloads_json=$(echo "$workloads_json" | jq --arg ns "$namespace" --arg kind "$kind" \
                    --arg name "$name" --argjson replicas "$replicas" \
                    '. + [{"namespace": $ns, "kind": $kind, "name": $name, "replicas": $replicas}]')
            fi
        done <<< "$pods"
    done <<< "$iscsi_pvcs"

    echo "$workloads_json"
}

# --- Command Help ---

usage_status() {
    cat <<EOF
Usage: $(basename "$0") status

Show iSCSI workloads and their current state.

Lists all Kubernetes deployments and statefulsets that use the synology-iscsi
storage class, along with their current replica counts.

Workloads scaled down by 'down' command are marked with their saved replica count.
EOF
    exit 0
}

usage_restart() {
    cat <<EOF
Usage: $(basename "$0") restart

Restart pods using iSCSI storage (quick recovery).

Deletes all pods that use synology-iscsi PVCs and waits for them to be
recreated and become healthy. This is useful for quick recovery from
minor iSCSI issues.

For storage maintenance (Synology reboots/updates), use 'down' and 'up'
instead, as restarting pods won't help if the LUNs have gone stale.
EOF
    exit 0
}

usage_down() {
    cat <<EOF
Usage: $(basename "$0") down

Scale down workloads for storage maintenance.

Discovers all workloads using synology-iscsi storage, annotates them with
their current replica count, then scales them all to 0 replicas.

This ensures clean iSCSI unmounts before storage goes offline (e.g., for
Synology DSM updates). Run 'up' after maintenance to restore workloads.

Annotation: $ANNOTATION_KEY
EOF
    exit 0
}

usage_up() {
    cat <<EOF
Usage: $(basename "$0") up

Restore workloads after storage maintenance.

Finds workloads annotated by 'down', scales them back to their original
replica counts, removes the annotation, and monitors pod health until
all are ready.

Annotation: $ANNOTATION_KEY
EOF
    exit 0
}

# --- Commands ---

cmd_status() {
    [[ "${1:-}" == "-h" || "${1:-}" == "--help" ]] && usage_status
    log_info "Discovering iSCSI workloads..."

    local workloads
    workloads=$(discover_workloads)

    local count
    count=$(echo "$workloads" | jq 'length')

    if [[ "$count" -eq 0 ]]; then
        log_warn "No workloads using iSCSI storage found"
        return 0
    fi

    log_info "Found $count workload(s) using iSCSI storage:"
    echo

    printf "%-20s %-15s %-30s %-10s %s\n" "NAMESPACE" "KIND" "NAME" "REPLICAS" "SAVED"
    printf "%-20s %-15s %-30s %-10s %s\n" "---------" "----" "----" "--------" "-----"

    local scaled_down_count=0
    echo "$workloads" | jq -r '.[] | "\(.namespace)\t\(.kind)\t\(.name)\t\(.replicas)"' | \
        while IFS=$'\t' read -r ns kind name replicas; do
            local annotation
            annotation=$(kubectl get "$kind" -n "$ns" "$name" \
                -o jsonpath="{.metadata.annotations['iscsi-storage/pre-maintenance-replicas']}" 2>/dev/null || echo "")
            local saved=""
            if [[ -n "$annotation" ]]; then
                saved="$annotation"
                scaled_down_count=$((scaled_down_count + 1))
            fi
            printf "%-20s %-15s %-30s %-10s %s\n" "$ns" "$kind" "$name" "$replicas" "$saved"
        done

    echo
    # Check for any scaled-down workloads
    local total_scaled=0
    while IFS=$'\t' read -r ns kind name replicas; do
        local annotation
        annotation=$(kubectl get "$kind" -n "$ns" "$name" \
            -o jsonpath="{.metadata.annotations['iscsi-storage/pre-maintenance-replicas']}" 2>/dev/null || echo "")
        if [[ -n "$annotation" ]]; then
            total_scaled=$((total_scaled + 1))
        fi
    done < <(echo "$workloads" | jq -r '.[] | "\(.namespace)\t\(.kind)\t\(.name)\t\(.replicas)"')

    if [[ "$total_scaled" -gt 0 ]]; then
        log_warn "$total_scaled workload(s) are scaled down for maintenance"
        log_warn "Run 'iscsi-storage up' to restore them"
    fi
}

cmd_restart() {
    [[ "${1:-}" == "-h" || "${1:-}" == "--help" ]] && usage_restart
    log_info "Finding iSCSI persistent volume claims..."
    local iscsi_pvcs
    iscsi_pvcs=$(discover_iscsi_pvcs)

    if [[ -z "$iscsi_pvcs" ]]; then
        log_warn "No synology-iscsi persistent volume claims found"
        return 0
    fi

    local pvc_count
    pvc_count=$(grep -c . <<< "$iscsi_pvcs" || echo 0)
    log_info "Found $pvc_count iSCSI PVC(s)"

    # Find all pods using these PVCs
    log_info "Finding pods using iSCSI-backed PVCs..."
    declare -A pod_to_delete
    declare -A pvcs_with_pods

    while IFS= read -r pvc_ref; do
        local namespace pvc_name
        namespace=$(echo "$pvc_ref" | cut -d/ -f1)
        pvc_name=$(echo "$pvc_ref" | cut -d/ -f2)

        local pods
        pods=$(find_pods_for_pvc "$namespace" "$pvc_name")
        local pods_trimmed
        pods_trimmed=$(echo "$pods" | tr -d '[:space:]')

        if [[ -n "$pods_trimmed" ]]; then
            pvcs_with_pods["$pvc_ref"]=1
            while IFS= read -r pod_name; do
                [[ -n "$pod_name" ]] && pod_to_delete["$namespace/$pod_name"]=1
            done <<< "$pods"
        fi
    done <<< "$iscsi_pvcs"

    if [[ ${#pod_to_delete[@]} -eq 0 ]]; then
        log_warn "No pods found using iSCSI storage"
        return 0
    fi

    log_info "Found ${#pod_to_delete[@]} pod(s) using iSCSI storage across ${#pvcs_with_pods[@]} PVC(s):"
    for pod_ref in "${!pod_to_delete[@]}"; do
        echo "  - $pod_ref"
    done

    echo
    read -p "$(echo -e "${YELLOW}Proceed with restarting ${#pod_to_delete[@]} pod(s)? [y/N]${NC} ")" -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_info "Aborted"
        return 0
    fi

    local overall_start_time
    overall_start_time=$(date +%s)

    # Delete all pods simultaneously
    log_info "Deleting all pods simultaneously..."
    for pod_ref in "${!pod_to_delete[@]}"; do
        local namespace pod_name
        namespace=$(echo "$pod_ref" | cut -d/ -f1)
        pod_name=$(echo "$pod_ref" | cut -d/ -f2)
        kubectl delete pod -n "$namespace" "$pod_name" --wait=false &
    done
    wait
    log_success "All delete commands issued"

    # Wait for old pods to terminate
    wait_for_pods_terminated pod_to_delete

    # Monitor pod recreation
    monitor_pod_health pvcs_with_pods

    local overall_elapsed
    overall_elapsed=$(($(date +%s) - overall_start_time))
    log_success "Pod restart completed successfully in ${overall_elapsed}s"
}

cmd_down() {
    [[ "${1:-}" == "-h" || "${1:-}" == "--help" ]] && usage_down

    log_info "Discovering iSCSI workloads..."
    local workloads
    workloads=$(discover_workloads)

    local count
    count=$(echo "$workloads" | jq 'length')

    if [[ "$count" -eq 0 ]]; then
        log_warn "No workloads using iSCSI storage found"
        return 0
    fi

    # Check for already-annotated workloads
    local already_down=0
    while IFS=$'\t' read -r ns kind name replicas; do
        local existing
        existing=$(kubectl get "$kind" -n "$ns" "$name" \
            -o jsonpath="{.metadata.annotations['$ANNOTATION_KEY']}" 2>/dev/null || echo "")
        if [[ -n "$existing" ]]; then
            log_warn "$ns/$kind/$name already scaled down: $existing"
            already_down=$((already_down + 1))
        fi
    done < <(echo "$workloads" | jq -r '.[] | "\(.namespace)\t\(.kind)\t\(.name)\t\(.replicas)"')

    if [[ "$already_down" -gt 0 ]]; then
        log_error "$already_down workload(s) already have maintenance annotations"
        log_error "Run 'iscsi-storage up' first to restore them"
        exit 1
    fi

    log_info "Found $count workload(s) to scale down:"
    echo "$workloads" | jq -r '.[] | "  - \(.namespace)/\(.kind)/\(.name) (replicas: \(.replicas))"'

    echo
    read -p "$(echo -e "${YELLOW}Scale down $count workload(s) to 0 replicas? [y/N]${NC} ")" -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_info "Aborted"
        return 0
    fi

    # Annotate and scale down all workloads
    local annotation_ts
    annotation_ts=$(date '+%Y-%m-%d %H:%M')
    log_info "Annotating and scaling down workloads..."

    while IFS=$'\t' read -r ns kind name replicas; do
        local annotation_value="$annotation_ts replicas=$replicas"
        log_info "Annotating $ns/$kind/$name: $annotation_value"
        kubectl annotate "$kind" -n "$ns" "$name" "$ANNOTATION_KEY=$annotation_value" --overwrite
        log_info "Scaling $ns/$kind/$name to 0"
        kubectl scale "$kind" -n "$ns" "$name" --replicas=0
    done < <(echo "$workloads" | jq -r '.[] | "\(.namespace)\t\(.kind)\t\(.name)\t\(.replicas)"')

    log_success "All workloads annotated and scaled"

    # Wait for pods to terminate
    log_info "Waiting for pods to terminate..."
    local start_time
    start_time=$(date +%s)

    while true; do
        local remaining=0
        while IFS=$'\t' read -r ns kind name; do
            local pod_count
            pod_count=$(kubectl get "$kind" -n "$ns" "$name" -o jsonpath='{.status.replicas}' 2>/dev/null || echo 0)
            [[ -z "$pod_count" ]] && pod_count=0
            remaining=$((remaining + pod_count))
        done < <(echo "$workloads" | jq -r '.[] | "\(.namespace)\t\(.kind)\t\(.name)"')

        local elapsed=$(($(date +%s) - start_time))

        if [[ "$remaining" -eq 0 ]]; then
            log_success "All pods terminated (${elapsed}s)"
            break
        fi

        log_info "Waiting for $remaining pod(s) to terminate (${elapsed}s)..."
        sleep 2
    done

    echo
    log_success "All iSCSI workloads scaled down"
    log_info "Safe to proceed with storage maintenance (Synology update, etc.)"
    log_info "Run 'iscsi-storage up' when maintenance is complete"
}

cmd_up() {
    [[ "${1:-}" == "-h" || "${1:-}" == "--help" ]] && usage_up

    log_info "Finding workloads with maintenance annotations..."

    # Find all deployments and statefulsets with our annotation
    local workloads_json="[]"

    # Check deployments
    local deps
    deps=$(kubectl get deployments -A -o json | jq -r --arg key "$ANNOTATION_KEY" \
        '.items[] | select(.metadata.annotations[$key] != null) | "\(.metadata.namespace)\t\(.metadata.name)\t\(.metadata.annotations[$key])"')

    while IFS=$'\t' read -r ns name annotation; do
        [[ -z "$ns" ]] && continue
        local replicas
        replicas=$(echo "$annotation" | grep -oP 'replicas=\K\d+' || echo "1")
        workloads_json=$(echo "$workloads_json" | jq --arg ns "$ns" --arg kind "deployment" \
            --arg name "$name" --argjson replicas "$replicas" --arg annotation "$annotation" \
            '. + [{"namespace": $ns, "kind": $kind, "name": $name, "replicas": $replicas, "annotation": $annotation}]')
    done <<< "$deps"

    # Check statefulsets
    local sts
    sts=$(kubectl get statefulsets -A -o json | jq -r --arg key "$ANNOTATION_KEY" \
        '.items[] | select(.metadata.annotations[$key] != null) | "\(.metadata.namespace)\t\(.metadata.name)\t\(.metadata.annotations[$key])"')

    while IFS=$'\t' read -r ns name annotation; do
        [[ -z "$ns" ]] && continue
        local replicas
        replicas=$(echo "$annotation" | grep -oP 'replicas=\K\d+' || echo "1")
        workloads_json=$(echo "$workloads_json" | jq --arg ns "$ns" --arg kind "statefulset" \
            --arg name "$name" --argjson replicas "$replicas" --arg annotation "$annotation" \
            '. + [{"namespace": $ns, "kind": $kind, "name": $name, "replicas": $replicas, "annotation": $annotation}]')
    done <<< "$sts"

    local count
    count=$(echo "$workloads_json" | jq 'length')

    if [[ "$count" -eq 0 ]]; then
        log_warn "No workloads found with maintenance annotations"
        log_info "Nothing to restore. Run 'iscsi-storage down' first."
        return 0
    fi

    log_info "Found $count workload(s) to restore:"
    echo "$workloads_json" | jq -r '.[] | "  - \(.namespace)/\(.kind)/\(.name) (\(.annotation))"'

    echo
    read -p "$(echo -e "${YELLOW}Restore $count workload(s)? [y/N]${NC} ")" -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_info "Aborted"
        return 0
    fi

    local overall_start_time
    overall_start_time=$(date +%s)

    # Scale up all workloads and remove annotations
    log_info "Scaling up workloads and removing annotations..."

    while IFS=$'\t' read -r ns kind name replicas; do
        log_info "Scaling $ns/$kind/$name to $replicas"
        kubectl scale "$kind" -n "$ns" "$name" --replicas="$replicas"
        log_info "Removing annotation from $ns/$kind/$name"
        kubectl annotate "$kind" -n "$ns" "$name" "$ANNOTATION_KEY-"
    done < <(echo "$workloads_json" | jq -r '.[] | "\(.namespace)\t\(.kind)\t\(.name)\t\(.replicas)"')

    log_success "All workloads scaled and annotations removed"

    # Monitor pod health
    log_info "Monitoring pod health..."
    local start_time
    start_time=$(date +%s)

    while true; do
        local ready=0
        local total=0
        local details=""

        while IFS=$'\t' read -r ns kind name replicas; do
            total=$((total + replicas))
            local ready_count
            ready_count=$(kubectl get "$kind" -n "$ns" "$name" -o jsonpath='{.status.readyReplicas}' 2>/dev/null || echo 0)
            [[ -z "$ready_count" ]] && ready_count=0
            ready=$((ready + ready_count))
            details="$details  $name: $ready_count/$replicas"
        done < <(echo "$workloads_json" | jq -r '.[] | "\(.namespace)\t\(.kind)\t\(.name)\t\(.replicas)"')

        local elapsed=$(($(date +%s) - start_time))

        if [[ "$ready" -eq "$total" ]]; then
            log_success "All pods ready ($ready/$total) in ${elapsed}s"
            break
        fi

        log_info "Pods ready: $ready/$total (${elapsed}s) -$details"
        sleep 2
    done

    local overall_elapsed
    overall_elapsed=$(($(date +%s) - overall_start_time))
    log_success "Workload restore completed successfully in ${overall_elapsed}s"
}

# Helper: wait for pods in associative array to terminate
wait_for_pods_terminated() {
    local -n pods_ref=$1
    local start_time
    start_time=$(date +%s)
    local check_interval=2
    local prev_count=-1

    while true; do
        local current_time elapsed terminating_count=0
        current_time=$(date +%s)
        elapsed=$((current_time - start_time))

        for pod_ref in "${!pods_ref[@]}"; do
            local namespace pod_name
            namespace=$(echo "$pod_ref" | cut -d/ -f1)
            pod_name=$(echo "$pod_ref" | cut -d/ -f2)
            if kubectl get pod -n "$namespace" "$pod_name" &>/dev/null; then
                terminating_count=$((terminating_count + 1))
            fi
        done

        if [[ $terminating_count -ne $prev_count ]]; then
            if [[ $terminating_count -eq 0 ]]; then
                log_success "All old pods terminated (${elapsed}s)"
            else
                log_info "Terminating: $terminating_count pods (${elapsed}s)"
            fi
            prev_count=$terminating_count
        fi

        [[ $terminating_count -eq 0 ]] && break
        sleep $check_interval
    done
}

# Helper: monitor pod health by PVC
monitor_pod_health() {
    local -n pvcs_ref=$1
    local start_time
    start_time=$(date +%s)
    local check_interval=2
    local total_pvcs=${#pvcs_ref[@]}
    declare -A prev_pvc_status

    while true; do
        local current_time elapsed
        current_time=$(date +%s)
        elapsed=$((current_time - start_time))

        declare -A current_pvc_status
        local ready_count=0 pending_count=0 starting_count=0 missing_count=0 failed_count=0

        for pvc_ref in "${!pvcs_ref[@]}"; do
            local namespace pvc_name
            namespace=$(echo "$pvc_ref" | cut -d/ -f1)
            pvc_name=$(echo "$pvc_ref" | cut -d/ -f2)

            local pod_name
            pod_name=$(kubectl get pods -n "$namespace" -o json 2>/dev/null | \
                jq -r --arg pvc "$pvc_name" \
                '.items[] | select(.spec.volumes[]?.persistentVolumeClaim?.claimName == $pvc) | .metadata.name' | head -1 || true)

            if [[ -z "$pod_name" ]]; then
                missing_count=$((missing_count + 1))
                current_pvc_status["$pvc_ref"]="No pod"
                continue
            fi

            local pod_json
            pod_json=$(kubectl get pod -n "$namespace" "$pod_name" -o json 2>/dev/null || echo "{}")

            if [[ "$pod_json" == "{}" ]]; then
                missing_count=$((missing_count + 1))
                current_pvc_status["$pvc_ref"]="Pod not found"
                continue
            fi

            local phase ready_status
            phase=$(echo "$pod_json" | jq -r '.status.phase // "Unknown"')
            ready_status=$(echo "$pod_json" | jq -r '([.status.conditions[]? | select(.type == "Ready")] | .[0].status) // "Unknown"')

            if [[ "$phase" == "Running" ]] && [[ "$ready_status" == "True" ]]; then
                ready_count=$((ready_count + 1))
                current_pvc_status["$pvc_ref"]="Ready"
            elif [[ "$phase" == "Running" ]]; then
                starting_count=$((starting_count + 1))
                current_pvc_status["$pvc_ref"]="Starting"
            elif [[ "$phase" == "Pending" ]]; then
                pending_count=$((pending_count + 1))
                local reason
                reason=$(echo "$pod_json" | jq -r '(.status.containerStatuses[0].state.waiting.reason) // ([.status.conditions[]? | select(.type == "PodScheduled" and .status == "False")] | .[0].reason) // "Pending"')

                if [[ "$reason" =~ ^(CrashLoopBackOff|ImagePullBackOff|ErrImagePull|ImageInspectError)$ ]]; then
                    failed_count=$((failed_count + 1))
                    current_pvc_status["$pvc_ref"]="Failed ($reason)"
                    log_error "$pvc_ref: Pod in terminal failure state - $reason"
                else
                    current_pvc_status["$pvc_ref"]="Pending ($reason)"
                fi
            elif [[ "$phase" == "Failed" ]] || [[ "$phase" == "Unknown" ]]; then
                failed_count=$((failed_count + 1))
                local reason
                reason=$(echo "$pod_json" | jq -r '.status.reason // .status.message // "Unknown"')
                current_pvc_status["$pvc_ref"]="Failed ($reason)"
                log_error "$pvc_ref: Pod failed - $reason"
            else
                current_pvc_status["$pvc_ref"]="$phase"
            fi
        done

        if [[ $failed_count -gt 0 ]]; then
            log_error "$failed_count pod(s) in terminal failure state - cannot continue"
            exit 1
        fi

        if [[ $ready_count -eq $total_pvcs ]]; then
            for pvc_ref in "${!current_pvc_status[@]}"; do
                local current_status="${current_pvc_status[$pvc_ref]}"
                local prev_status="${prev_pvc_status[$pvc_ref]:-}"
                if [[ "$current_status" != "$prev_status" && "$current_status" == "Ready" ]]; then
                    log_success "$pvc_ref: $current_status"
                fi
            done
            log_success "All $total_pvcs PVCs have ready pods"
            break
        fi

        for pvc_ref in "${!current_pvc_status[@]}"; do
            local current_status="${current_pvc_status[$pvc_ref]}"
            local prev_status="${prev_pvc_status[$pvc_ref]:-}"
            if [[ "$current_status" != "$prev_status" ]]; then
                if [[ "$current_status" == "Ready" ]]; then
                    log_success "$pvc_ref: $current_status"
                else
                    log_info "$pvc_ref: $current_status"
                fi
            fi
        done

        log_info "PVCs (${elapsed}s): Ready: $ready_count/$total_pvcs, Pending: $pending_count, Starting: $starting_count, Missing: $missing_count"

        unset prev_pvc_status
        declare -A prev_pvc_status
        for pvc_ref in "${!current_pvc_status[@]}"; do
            prev_pvc_status["$pvc_ref"]="${current_pvc_status[$pvc_ref]}"
        done

        sleep $check_interval
    done
}

# --- Main ---

[[ $# -lt 1 ]] && usage

cmd="${1:-}"
shift || true

case "$cmd" in
    status)  cmd_status "$@" ;;
    restart) cmd_restart "$@" ;;
    down)    cmd_down "$@" ;;
    up)      cmd_up "$@" ;;
    -h|--help|help) usage ;;
    *)
        log_error "Unknown command: $cmd"
        usage
        ;;
esac
